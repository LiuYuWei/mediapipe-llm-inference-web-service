# mediapipe-llm-inference-web-service
Use MediaPipe LLM Inference API to chat with LLM in UI

## Overview
This web sample demonstrates how to use the LLM Inference API to run common text-to-text generation tasks like information retrieval, email drafting, and document summarization, on web.

## Prerequisites
A browser with WebGPU support (eg. Chrome on macOS or Windows).

## Running the demo
Follow the following instructions to run the sample on your device:

